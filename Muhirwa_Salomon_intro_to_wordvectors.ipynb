{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Muhirwakyeyune/AMMI-NATURAL-LANGUAGE-PROCESSING/blob/main/Muhirwa_Salomon_intro_to_wordvectors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngOr248LZ4dA"
      },
      "source": [
        "\n",
        "<h1 style=\"font-family:verdana;font-size:300%;text-align:center;background-color:#f2f2f2;color:#0d0d0d\">AMMI NLP - Review sessions</h1>\n",
        "\n",
        "<h1 style=\"font-family:verdana;font-size:180%;text-align:Center;color:#993333\"> Lab 2: Introduction to wordvectors </h1>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJT7Jyr6aXpn",
        "outputId": "dee3bbde-47f2-41ed-c261-8c0b834c4330"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ocwsf1KZ4dE"
      },
      "source": [
        "**Big thanks to Amr Khalifa who improved this lab and made it to a Jupyter Notebook!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RsfqKuOLZ4dE"
      },
      "outputs": [],
      "source": [
        "import io, sys\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "qQy_jY7CZ4dG"
      },
      "outputs": [],
      "source": [
        "def load_vectors(filename):\n",
        "    fin = io.open(filename, 'r', encoding='utf-8', newline='\\n')\n",
        "    n, d = map(int, fin.readline().split())\n",
        "    data = {}\n",
        "    for line in fin:\n",
        "        tokens = line.rstrip().split(' ')\n",
        "        data[tokens[0]] = np.asarray([float(x) for x in tokens[1:]])\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "B-1OUrRIZ4dG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5960869e-fb34-4b91-e6f1-31f7b3074f0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ** Word vectors ** \n",
            "\n",
            "<class 'numpy.ndarray'> 300\n"
          ]
        }
      ],
      "source": [
        "# Loading word vectors\n",
        "\n",
        "print('')\n",
        "print(' ** Word vectors ** ')\n",
        "print('')\n",
        "\n",
        "'''\n",
        "word_vectors is a dictionary that maps words to their numerical word vector\n",
        "[word (string)] = [np-array]\n",
        "'''\n",
        "word_vectors = load_vectors('/content/drive/MyDrive/session2/wiki.en.vec')\n",
        "\n",
        "tree_vector = word_vectors['tree']\n",
        "print(type(tree_vector), len(tree_vector))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "XgUjxOHtZ4dH"
      },
      "outputs": [],
      "source": [
        "## This function computes the cosine similarity between vectors u and v\n",
        "\n",
        "def cosine(u, v):\n",
        "    '''\n",
        "    Parameters:\n",
        "    u : 1-D numpy array\n",
        "    v : 1-D numpy array\n",
        "\n",
        "    Returns:\n",
        "    cos (float) : value of the cosine similairy between vectors u, v\n",
        "    '''\n",
        "\n",
        "    ## FILL CODE\n",
        "    dot_product=np.dot(u, v)\n",
        "    norm_u = np.linalg.norm(u)\n",
        "    norm_v = np.linalg.norm(v)\n",
        "    cos = dot_product / (norm_u * norm_v)\n",
        "\n",
        "\n",
        "    return cos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "He-jidFbZ4dH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b896aa3-7534-4ff7-9094-b56d22bffb9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "similarity(apple, apples) = 0.637\n",
            "similarity(apple, banana) = 0.431\n",
            "similarity(apple, tiger) = 0.212\n"
          ]
        }
      ],
      "source": [
        "# compute similarity between words\n",
        "\n",
        "print('similarity(apple, apples) = %.3f' %\n",
        "      cosine(word_vectors['apple'], word_vectors['apples']))\n",
        "print('similarity(apple, banana) = %.3f' %\n",
        "      cosine(word_vectors['apple'], word_vectors['banana']))\n",
        "print('similarity(apple, tiger) = %.3f' %\n",
        "      cosine(word_vectors['apple'], word_vectors['tiger']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "SVcjkMLQZ4dH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nearest_neighbor(x, word_vectors, exclude_words=[]):\n",
        "    '''\n",
        "    Parameters:\n",
        "    x (string): word to find its nearest neighbour\n",
        "    word_vectors (Python dict): {word (string): np-array of word vector}\n",
        "    exclude_words (list of strings): words to be excluded from the search\n",
        "\n",
        "    Returns:\n",
        "    best_word (string) : the word whose word vector is the nearest neighbour\n",
        "    to the word vector of x\n",
        "    '''\n",
        "    best_score = -1.0\n",
        "    best_word = None\n",
        "\n",
        "    # Iterate through each word in the word_vectors dictionary\n",
        "    for word, vector in word_vectors.items():\n",
        "        # Check if the word should be excluded from the search\n",
        "        if word in exclude_words:\n",
        "            continue\n",
        "\n",
        "        # Calculate the cosine similarity score between x and the current word vector\n",
        "        score = cosine(x, vector)  # cosine() is a function to calculate cosine similarity\n",
        "\n",
        "        # Update the best score and best word if the current score is higher\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_word = word\n",
        "\n",
        "    # Return the word with the highest similarity score (nearest neighbor)\n",
        "    return best_word\n"
      ],
      "metadata": {
        "id": "PNapymrS0BCX"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Vk8swgh3Z4dI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91c2506e-5e7e-4f68-89b5-587b16aadccd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The nearest neighbor of cat is: dog\n"
          ]
        }
      ],
      "source": [
        "print('')\n",
        "print('The nearest neighbor of cat is: ' +\n",
        "      nearest_neighbor(word_vectors['cat'], word_vectors, exclude_words = ['cat', 'cats']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGjkVbNaZ4dI"
      },
      "source": [
        "#### Hint (using python priorty queues with the heapq datastructure):\n",
        "if you don't want to store all the words and scores you can use the priortiy queue and only store the best K element so far."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import heapq\n",
        "import numpy as np\n",
        "\n",
        "## This function returns the words corresponding to the\n",
        "## K nearest neighbors of vector x.\n",
        "## You can use the functions heappush and heappop.\n",
        "\n",
        "def knn(x, vectors, k):\n",
        "    '''\n",
        "    Parameters:\n",
        "    x (string): word to find its nearest neighbour\n",
        "    vectors (Python dict): {word (string): np-array of word vector}\n",
        "    k (int): number of nearest neighbours to be found\n",
        "\n",
        "    Returns:\n",
        "    k_nearest_neighbors (list of tuples): [(score, word), (score, word), ....]\n",
        "    '''\n",
        "\n",
        "    k_nearest_neighbors = []\n",
        "    x_vector = vectors[x]  # Fetch the word vector corresponding to x\n",
        "\n",
        "    for word, vector in vectors.items():\n",
        "        if word != x:\n",
        "            score = -np.linalg.norm(vector - x_vector)  # Negative Euclidean distance for max heap\n",
        "            heapq.heappush(k_nearest_neighbors, (score, word))\n",
        "\n",
        "            if len(k_nearest_neighbors) > k:\n",
        "                heapq.heappop(k_nearest_neighbors)\n",
        "\n",
        "    k_nearest_neighbors = sorted(k_nearest_neighbors, key=lambda x: x[0], reverse=True)\n",
        "\n",
        "    return k_nearest_neighbors\n",
        "\n"
      ],
      "metadata": {
        "id": "psHXpfUmj6fh"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "knn_cat = knn('cat', word_vectors, 5)  # Pass 'cat' as the word, not the vector\n",
        "print('')\n",
        "print('cat')\n",
        "print('--------------')\n",
        "for score, word in knn_cat:\n",
        "    print(word + '\\t%.3f' % score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rx3ls8Aw2WK4",
        "outputId": "32819a2d-0ddb-442f-b1c6-8b13a53b90b4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "cat\n",
            "--------------\n",
            "cats\t-3.225\n",
            "dog\t-3.478\n",
            "pet\t-3.889\n",
            "dogs\t-4.050\n",
            "rabbit\t-4.065\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnbwpPkfZ4dJ"
      },
      "source": [
        "#### Hint:\n",
        "To find the analogies, we find the nearest neighbour associated with the wordvector d\n",
        "$$ d = \\frac{c}{\\Vert {c} \\Vert} + \\frac{b}{\\Vert {b} \\Vert} - \\frac{a}{\\Vert {a} \\Vert}$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izyQv28LZ4dJ"
      },
      "outputs": [],
      "source": [
        "## This function return the words d, such that a:b and c:d\n",
        "## verifies the same relation\n",
        "\n",
        "def analogy(a, b, c, word_vectors):\n",
        "    '''\n",
        "    Parameters:\n",
        "    a (string): word a\n",
        "    b (string): word b\n",
        "    c (string): word c\n",
        "    word_vectors (Python dict): {word (string): np-array of word vector}\n",
        "\n",
        "    Returnrs:\n",
        "    the word d (string) associated with c such that c:d is similar to a:b\n",
        "\n",
        "    '''\n",
        "\n",
        "    ## FILL CODE\n",
        "\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def analogy(a, b, c, word_vectors):\n",
        "    '''\n",
        "    Parameters:\n",
        "    a (string): word a\n",
        "    b (string): word b\n",
        "    c (string): word c\n",
        "    word_vectors (Python dict): {word (string): np-array of word vector}\n",
        "\n",
        "    Returns:\n",
        "    the word d (string) associated with c such that c:d is similar to a:b\n",
        "    '''\n",
        "\n",
        "    # Retrieve the word vectors for a, b, and c from the word_vectors dictionary\n",
        "    a_vector = word_vectors[a]\n",
        "    b_vector = word_vectors[b]\n",
        "    c_vector = word_vectors[c]\n",
        "\n",
        "    # Compute the vector d using the provided equation\n",
        "    d_vector = c_vector / np.linalg.norm(c_vector) + (b_vector / np.linalg.norm(b_vector)) - (a_vector / np.linalg.norm(a_vector))\n",
        "\n",
        "    # Initialize variables for tracking the best score and best word\n",
        "    best_score = -1.0\n",
        "    best_word = None\n",
        "\n",
        "    # Iterate over the word vectors in the word_vectors dictionary\n",
        "    for word, vector in word_vectors.items():\n",
        "        # Exclude a, b, and c from consideration\n",
        "        if word != a and word != b and word != c:\n",
        "            # Calculate the cosine similarity score between the word vector and d_vector\n",
        "            score = np.dot(vector, d_vector) / (np.linalg.norm(vector) * np.linalg.norm(d_vector))\n",
        "            # Update the best_score and best_word if a higher score is found\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_word = word\n",
        "\n",
        "    # Return the best_word, which is the word d associated with c that satisfies the analogy relation\n",
        "    return best_word\n"
      ],
      "metadata": {
        "id": "tjyoXzFl6j-Y"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "S5fiPKCYZ4dJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2557c461-d97f-46b7-a99c-568489dba48d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "france - paris + rome = italy\n"
          ]
        }
      ],
      "source": [
        "# Word analogies\n",
        "\n",
        "print('')\n",
        "print('france - paris + rome = ' + analogy('paris', 'france', 'rome', word_vectors))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqyk-1BuZ4dJ"
      },
      "source": [
        "## A word about biases in word vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "TcNhECauZ4dJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e16300f7-016d-4cd4-d32f-c205b13b1c18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "similarity(genius, man) = 0.445\n",
            "similarity(genius, woman) = 0.325\n"
          ]
        }
      ],
      "source": [
        "## A word about biases in word vectors:\n",
        "\n",
        "print('')\n",
        "print('similarity(genius, man) = %.3f' %\n",
        "      cosine(word_vectors['man'], word_vectors['genius']))\n",
        "print('similarity(genius, woman) = %.3f' %\n",
        "      cosine(word_vectors['woman'], word_vectors['genius']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Dd6gcUcpZ4dJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def association_strength(w, A, B, vectors):\n",
        "    '''\n",
        "    Parameters:\n",
        "    w (string): word w\n",
        "    A (list of strings): The words belonging to set A\n",
        "    B (list of strings): The words belonging to set B\n",
        "    vectors (Python dict): {word (string): np-array of word vector}\n",
        "\n",
        "    Returns:\n",
        "    strength (float): the value of the association strength\n",
        "    '''\n",
        "\n",
        "    strength = 0.0\n",
        "    part_a = 0.0\n",
        "    part_b = 0.0\n",
        "\n",
        "    # Compute part_a: the average similarity between word w and the words in set A\n",
        "    for word in A:\n",
        "        part_a += np.dot(vectors[w], vectors[word]) / (np.linalg.norm(vectors[w]) * np.linalg.norm(vectors[word]))\n",
        "    part_a /= len(A)\n",
        "\n",
        "    # Compute part_b: the average similarity between word w and the words in set B\n",
        "    for word in B:\n",
        "        part_b += np.dot(vectors[w], vectors[word]) / (np.linalg.norm(vectors[w]) * np.linalg.norm(vectors[word]))\n",
        "    part_b /= len(B)\n",
        "\n",
        "    # Compute the association strength by subtracting part_b from part_a\n",
        "    strength = part_a - part_b\n",
        "\n",
        "    return strength\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Z9PcJB1YZ4dJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def weat(X, Y, A, B, vectors):\n",
        "    '''\n",
        "    Parameters:\n",
        "    X (list of strings): The words belonging to set X\n",
        "    Y (list of strings): The words belonging to set Y\n",
        "    A (list of strings): The words belonging to set A\n",
        "    B (list of strings): The words belonging to set B\n",
        "    vectors (Python dict): {word (string): np-array of word vector}\n",
        "\n",
        "    Returns:\n",
        "    score (float): the value of the group association strength\n",
        "    '''\n",
        "\n",
        "    score = 0.0\n",
        "\n",
        "    # Compute the association strength for each word in set X\n",
        "    for x in X:\n",
        "        score_x = association_strength(x, A, B, vectors)\n",
        "        score += score_x\n",
        "\n",
        "    # Compute the association strength for each word in set Y\n",
        "    for y in Y:\n",
        "        score_y = association_strength(y, A, B, vectors)\n",
        "        score -= score_y\n",
        "\n",
        "    return score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "f4C8KwJnZ4dK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95b500da-fb6b-4f83-9450-b08015830ca8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Word embedding association test: 0.847\n"
          ]
        }
      ],
      "source": [
        "## Replicate one of the experiments from:\n",
        "##\n",
        "## Semantics derived automatically from language corpora contain human-like biases\n",
        "## Caliskan, Bryson, Narayanan (2017)\n",
        "\n",
        "career = ['executive', 'management', 'professional', 'corporation',\n",
        "          'salary', 'office', 'business', 'career']\n",
        "family = ['home', 'parents', 'children', 'family',\n",
        "          'cousins', 'marriage', 'wedding', 'relatives']\n",
        "male = ['john', 'paul', 'mike', 'kevin', 'steve', 'greg', 'jeff', 'bill']\n",
        "female = ['amy', 'joan', 'lisa', 'sarah', 'diana', 'kate', 'ann', 'donna']\n",
        "\n",
        "print('')\n",
        "print('Word embedding association test: %.3f' %\n",
        "      weat(career, family, male, female, word_vectors))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeJ1nCy9Z4dK"
      },
      "source": [
        "## Word translation using word vectors\n",
        "\n",
        "In the following, we will use word vectors in English and French to translate words from English to French. The idea is to learn a linear function that maps English word vectors to their correponding French word vectors. To learn this linear mapping, we will use a small bilingual lexicon, that contains pairs of words in English and French that are translations of each other.\n",
        "\n",
        "The following function will load the small English-French bilingual lexicon:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "by8ZxSTnZ4dK"
      },
      "outputs": [],
      "source": [
        "def load_lexicon(filename):\n",
        "    '''\n",
        "    Parameters:\n",
        "    filename(string): the path of the lexicon\n",
        "\n",
        "    Returns:\n",
        "    data(list of pairs of string): the bilingual lexicon\n",
        "    '''\n",
        "    fin = io.open(filename, 'r', encoding='utf-8', newline='\\n')\n",
        "    data = []\n",
        "    for line in fin:\n",
        "        a, b = line.rstrip().split(' ')\n",
        "        data.append((a, b))\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "rqJwXamQZ4dK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba6a9355-ee6c-4365-cd7b-18ac06236ac9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('the', 'le'), ('the', 'les'), ('the', 'la'), ('and', 'et'), ('was', 'fut')]\n"
          ]
        }
      ],
      "source": [
        "word_vectors_en = load_vectors('/content/drive/MyDrive/session2/wiki.en.vec')\n",
        "word_vectors_fr = load_vectors('/content/drive/MyDrive/session2/wiki.en.vec')\n",
        "lexicon = load_lexicon(\"/content/drive/MyDrive/session2/lexicon-en-fr.txt\")\n",
        "print(lexicon[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "FxkVZWtNZ4dK"
      },
      "outputs": [],
      "source": [
        "# We split the lexicon into a train and validation set\n",
        "train = lexicon[:5000]\n",
        "valid = lexicon[5000:5100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbIfB0_kZ4dK"
      },
      "source": [
        "The following function will learn the mapping from English to French. The idea is to build two matrices $X_{\\text{en}}$ and $X_{\\text{fr}}$, and to find a mapping $M$ that minimizes $||X_{\\text{en}} W - X_{\\text{fr}} ||_2$. In numpy, this mapping can be obtained by using the `numpy.linalg.lstsq` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "X3h1IlafZ4dK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def align(word_vectors_en, word_vectors_fr, lexicon):\n",
        "    '''\n",
        "    Parameters:\n",
        "    word_vectors_en(dict: string -> np.array): English word vectors\n",
        "    word_vectors_en(dict: string -> np.array): French word vectors\n",
        "    lexicon(list of pairs of string): bilingual training lexicon\n",
        "\n",
        "    Returns\n",
        "    mapping(np.array): the mapping from English to French vectors\n",
        "    '''\n",
        "    x_en, x_fr = [], []\n",
        "\n",
        "    # Gather corresponding word vectors from the lexicon\n",
        "    for en_word, fr_word in lexicon:\n",
        "        if en_word in word_vectors_en and fr_word in word_vectors_fr:\n",
        "            x_en.append(word_vectors_en[en_word])\n",
        "            x_fr.append(word_vectors_fr[fr_word])\n",
        "\n",
        "    # Convert the lists to numpy arrays\n",
        "    x_en = np.array(x_en)\n",
        "    x_fr = np.array(x_fr)\n",
        "\n",
        "    # Perform alignment or mapping between the vectors\n",
        "    mapping = np.linalg.lstsq(x_en, x_fr, rcond=None)[0]\n",
        "\n",
        "    return mapping\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "I21S_5joZ4dK"
      },
      "outputs": [],
      "source": [
        "mapping = align(word_vectors_en, word_vectors_fr, lexicon)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ym1c9Ex3Z4dK"
      },
      "source": [
        "Given a mapping, a set of word English word vector and French word vectors, the next function will translate the English word to French. To do so, we apply the mapping on the English word, and retrieve the nearest neighbor of the obtained vector in the set of French word vectors. The translation is then the corresponding French word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "1zhnO90hZ4dK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def translate(word, word_vectors_en, word_vectors_fr, mapping):\n",
        "    '''\n",
        "    Parameters:\n",
        "    word(string): an English word\n",
        "    word_vectors_en(dict: string -> np.array): English word vectors\n",
        "    word_vectors_en(dict: string -> np.array): French word vectors\n",
        "    mapping(np.array): the mapping from English to French vectors\n",
        "\n",
        "    Returns\n",
        "    A string containing the translation of the English word\n",
        "    '''\n",
        "\n",
        "    # Check if the word is present in the English word vectors\n",
        "    if word in word_vectors_en:\n",
        "        # Get the English word vector\n",
        "        en_vector = word_vectors_en[word]\n",
        "        # Perform translation using the mapping\n",
        "        fr_vector = np.dot(mapping, en_vector)\n",
        "\n",
        "        # Find the closest French word to the translated vector\n",
        "        closest_word = None\n",
        "        min_distance = float('inf')\n",
        "        for fr_word, fr_vector_word in word_vectors_fr.items():\n",
        "            distance = np.linalg.norm(fr_vector_word - fr_vector)\n",
        "            if distance < min_distance:\n",
        "                closest_word = fr_word\n",
        "                min_distance = distance\n",
        "\n",
        "        return closest_word\n",
        "\n",
        "    # Return None if the word is not found in the English word vectors\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "6RlT1nxPZ4dL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7db8af75-7619-4cd1-d25f-7dc35f5c2e05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "world\n",
            "machine\n",
            "learning\n"
          ]
        }
      ],
      "source": [
        "print(translate(\"world\", word_vectors_en, word_vectors_fr, mapping))\n",
        "print(translate(\"machine\", word_vectors_en, word_vectors_fr, mapping))\n",
        "print(translate(\"learning\", word_vectors_en, word_vectors_fr, mapping))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8JCZpnIZ4dL"
      },
      "source": [
        "Finally, let's implement a function to evaluate this method on the validation lexicon:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "SmiylyyNZ4dL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def evaluate(valid, word_vectors_en, word_vectors_fr, mapping):\n",
        "    '''\n",
        "    Parameters:\n",
        "    valid(a list of pairs of string): the validation lexicon\n",
        "    word_vectors_en(dict: string -> np.array): English word vectors\n",
        "    word_vectors_en(dict: string -> np.array): French word vectors\n",
        "    mapping(np.array): the mapping from English to French vectors\n",
        "\n",
        "    Returns\n",
        "    Accuracy(float): the accuracy on the validation lexicon\n",
        "    '''\n",
        "    acc, n = 0.0, 0\n",
        "\n",
        "    for en_word, fr_word in valid:\n",
        "        # Check if both English and French words are present in their respective word vectors\n",
        "        if en_word in word_vectors_en and fr_word in word_vectors_fr:\n",
        "            # Translate English word to French\n",
        "            translated_word = translate(en_word, word_vectors_en, word_vectors_fr, mapping)\n",
        "            # Check if the translation matches the expected French word\n",
        "            if translated_word == fr_word:\n",
        "                acc += 1\n",
        "            n += 1\n",
        "\n",
        "    # Calculate the accuracy by dividing the number of correct translations by the total number of translations\n",
        "    accuracy = acc / n if n > 0 else 0.0\n",
        "\n",
        "    return accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "l1f9yEeTZ4dL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e67c09e6-b1f1-4617-c19c-e5d30fd4c959"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7727272727272727"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "evaluate(valid, word_vectors_en, word_vectors_fr, mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jPH8uOKZ4dL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2+"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}